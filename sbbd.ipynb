{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a45be2",
   "metadata": {
    "id": "b8a45be2"
   },
   "source": [
    "# 1-  Data crawling on TwitterAPI: Full-archive search \n",
    "\n",
    "Documentation: https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-all \n",
    "\n",
    "Endpoint URL: https://api.twitter.com/2/tweets/search/all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e68fd6",
   "metadata": {
    "id": "54e68fd6"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import urllib.request as urllib2\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "auth_token = os.environ.get('AUTH_TOKEN')\n",
    "header = {'Authorization': 'Bearer ' + auth_token}\n",
    "\n",
    "class TwitterHook():\n",
    "\n",
    "    def __init__(self, query, header = None, start_time = None, end_time = None, max_results= None):\n",
    "        self.query = query\n",
    "        self.header = header\n",
    "        self.start_time = '2020-02-29T00%3A00%3A00Z'\n",
    "        self.end_time = '2021-05-04T00%3A00%3A00Z'\n",
    "        self.max_results = '500'\n",
    "\n",
    "    def create_url(self):\n",
    "        query = self.query\n",
    "        start_time = self.start_time\n",
    "        end_time = self.end_time        \n",
    "        \n",
    "        tweet_fields = \"tweet.fields=author_id,id,created_at,in_reply_to_user_id,text\"\n",
    "        user_fields = \"expansions=author_id&user.fields=id,name,username,created_at\"\n",
    "        start_time = (\n",
    "            f\"&start_time={self.start_time}\"\n",
    "            if self.start_time\n",
    "            else \"\"\n",
    "        )\n",
    "        end_time = (\n",
    "            f\"&end_time={self.end_time}\"\n",
    "            if self.end_time\n",
    "            else \"\"\n",
    "        )\n",
    "        max_results  = (\n",
    "            f\"&max_results={self.max_results}\"\n",
    "            if self.max_results\n",
    "            else \"\"\n",
    "        )\n",
    "        url = \"https://api.twitter.com/2/tweets/search/all?query={}&{}&{}{}{}{}\".format(\n",
    "               query, tweet_fields, user_fields, start_time, end_time, max_results\n",
    "        )\n",
    "        return url\n",
    "\n",
    "    def connect_to_endpoint(self, url, header):\n",
    "        response = requests.get(url,headers=header)\n",
    "        listOfTweets = json.loads(response.content)\n",
    "        return  listOfTweets\n",
    "\n",
    "\n",
    "    def paginate(self, url, header, next_token=\"\"):\n",
    "        if next_token:\n",
    "            full_url = f\"{url}&next_token={next_token}\"\n",
    "            print('New Request on',full_url)\n",
    "        else:\n",
    "            full_url = url\n",
    "            print('New Request on',full_url)\n",
    "        data = self.connect_to_endpoint(full_url, header)\n",
    "        yield data\n",
    "        if \"next_token\" in data.get(\"meta\", {}):\n",
    "            yield from self.paginate(url, header, data['meta']['next_token'])\n",
    "\n",
    "\n",
    "    def run(self):  \n",
    "        url = self.create_url()\n",
    "        yield from self.paginate(url, header)\n",
    "        \n",
    "        \n",
    "def GetTweets(query):\n",
    "    tweets = pd.DataFrame()\n",
    "    for pg in TwitterHook(query).run():\n",
    "        time.sleep(1)  \n",
    "        \n",
    "        if 'data' in pg:\n",
    "            tweets =  tweets.append(pg['data'],ignore_index=True)\n",
    "        else:\n",
    "             print('Missing request')\n",
    "        \n",
    "    print('Done! Total of', len(tweets), 'tweets collected.')\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a16896",
   "metadata": {
    "id": "61a16896",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = GetTweets(urllib2.quote('#vacinanao -rt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222cf05",
   "metadata": {
    "id": "a222cf05"
   },
   "source": [
    "# 2- Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66004b1c",
   "metadata": {},
   "source": [
    "### Import datasets from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aPg7p1mOUht",
   "metadata": {
    "id": "2aPg7p1mOUht"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "downloaded = drive.CreateFile({'id':\"1kzlbUH76yT_J4sMj8ZMf0ZsyrpNK0uhX\"}) \n",
    "downloaded.GetContentFile('provaxxersProcessed.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "provaxxers =  pd.read_csv('./provaxxersProcessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d741672d",
   "metadata": {},
   "source": [
    "### Import datasets from local disck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47550598",
   "metadata": {
    "id": "47550598"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "antivaxxers = pd.read_csv('./datasets/antivaxxersTweets.csv', low_memory=False)\n",
    "provaxxers = pd.read_csv('./datasets/provaxxersTweets.csv', low_memory=False)\n",
    "\n",
    "start_date ='2020-03-11T00:59:59.000Z'\n",
    "end_date = '2022-04-06T00:00:00.000Z'\n",
    "\n",
    "mask_provaxxers = (provaxxers['created_at'] >= start_date) & (provaxxers['created_at'] <= end_date)\n",
    "provaxxers = provaxxers.loc[mask_provaxxers]\n",
    "\n",
    "mask_antivaxxers = (antivaxxers['created_at'] >= start_date) & (antivaxxers['created_at'] <= end_date)\n",
    "antivaxxers = antivaxxers.loc[mask_antivaxxers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734080d",
   "metadata": {},
   "source": [
    "### Pre-proccess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16ca83",
   "metadata": {
    "id": "ae16ca83"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "import numpy as np \n",
    "from string import punctuation\n",
    "import unidecode\n",
    "stemmer = nltk.RSLPStemmer()\n",
    "\n",
    "\n",
    "def proccess_text(tweets):\n",
    "    \n",
    "    # Removing links, mentions and hashtags\n",
    "    tweets['processed_text'] = tweets.text.str.replace(r'(http\\S+)', '',regex=True) \\\n",
    "                                          .str.replace(r'@[\\w]*', '',regex=True) \\\n",
    "                                          .str.replace(r'#[\\w]*','',regex=True) \n",
    "    print('[ok] - Removing links.')\n",
    "    print('[ok] - Removing mentions.')\n",
    "    print('[ok] - Removing hashtags.')\n",
    "\n",
    "    textWords = ' '.join([text for text in tweets.processed_text])\n",
    "\n",
    "    # Removing accent\n",
    "    textWords = [unidecode.unidecode(text) for text in tweets.processed_text ]    \n",
    "    print('[ok] - Removing accent.')\n",
    "    \n",
    "    # Creating a list of words and characters (stopwords) to be removed from the text\n",
    "    # stopWords = nltk.corpus.stopwords.words(\"portuguese\")    \n",
    "    print('[ok] - Creating a list of words and characters (stopwords) to be removed from the text.')\n",
    "    \n",
    "    \n",
    "    # Separating punctuation from words\n",
    "    punctSeparator = tokenize.WordPunctTokenizer()\n",
    "    punctuationList = list()\n",
    "    for punct in punctuation:\n",
    "        punctuationList.append(punct)\n",
    "        \n",
    "    #stopWords =   punctuationList + stopWords    \n",
    "    stopWords =   punctuationList\n",
    "    #print('[ok] - Separating punctuation from words.')\n",
    "\n",
    "\n",
    "    # Iterating over the text and removing stop words \n",
    "    trasnformedText = list()    \n",
    "    for text in textWords:\n",
    "        newText = list()   \n",
    "        text = text.lower()\n",
    "        textWords = punctSeparator.tokenize(text)\n",
    "        for words in textWords:\n",
    "             if words not in stopWords:\n",
    "                #newText.append(stemmer.stem(words))\n",
    "                newText.append(words)\n",
    "        trasnformedText.append(' '.join(newText))\n",
    "    tweets.processed_text = trasnformedText\n",
    "    print('[ok] - Removing punctuation and set text to lowecase.')\n",
    "   \n",
    "    # Removing all non-text characters\n",
    "    tweets.processed_text = tweets['processed_text'].str.replace(r\"[^a-zA-Z#]\", \" \", regex=True)                                                         \n",
    "    print('[ok] - Removing all non-text characters.')\n",
    "   \n",
    "    trasnformedText = list()\n",
    "    for phrase in tweets.processed_text:\n",
    "        newPhrase = list()   \n",
    "        newPhrase.append(' '.join(phrase.split()))\n",
    "        for words in newPhrase:\n",
    "            trasnformedText.append(''.join(newPhrase))\n",
    "    tweets.processed_text = trasnformedText\n",
    "    \n",
    "    # Removing tweets with less than three terms\n",
    "    index=[x for x in tweets.index if tweets.processed_text[x].count(' ') < 3]\n",
    "    tweets = tweets.drop(index)\n",
    "    print('[ok] - Removing tweets with less than three terms.')\n",
    "\n",
    "    # Removing empty lines\n",
    "    removeEmpty  = tweets.processed_text != ' '\n",
    "    tweets = tweets[removeEmpty]\n",
    "    print('[ok] - Removing empty lines.')\n",
    "\n",
    "    tweets.reset_index(inplace=True)\n",
    "    tweets = {'created_at': tweets.created_at, 'id':tweets.id,'author_id':tweets.author_id,'in_reply_to_user_id':tweets.in_reply_to_user_id, 'text': tweets.processed_text}\n",
    "    #tweets = {'text': tweets.processed_text,'stance':tweets.stance}\n",
    "    tweets = pd.DataFrame(tweets)\n",
    "    tweets = tweets.sort_values(['created_at']).reset_index().drop(columns=[\"index\"])\n",
    "    #tweets = tweets.reset_index().drop(columns=[\"index\"])\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759d176",
   "metadata": {
    "id": "c759d176"
   },
   "outputs": [],
   "source": [
    "provaxxers = proccess_text(provaxxers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2cf6c",
   "metadata": {
    "id": "3bd2cf6c"
   },
   "source": [
    "# 3- Topic Modeling with BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6509094",
   "metadata": {
    "id": "e6509094"
   },
   "source": [
    "### Checking GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5968c368",
   "metadata": {
    "id": "5968c368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():        \n",
    "    device = torch.device(\"cuda\")    \n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25c68ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 28 11:10:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.13       Driver Version: 512.13       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 31%   33C    P8     4W / 175W |   1811MiB /  8192MiB |     11%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1644    C+G                                   N/A      |\n",
      "|    0   N/A  N/A      3840    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      4368    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      5884    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      8564      C   ...\\inf\\Anaconda3\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     10528    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11056    C+G   ...zpdnekdrzrea0\\Spotify.exe    N/A      |\n",
      "|    0   N/A  N/A     11136    C+G   ...185.50\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     13444    C+G   ...185.50\\msedgewebview2.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757b7ac",
   "metadata": {},
   "source": [
    "### Checking RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f160a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 16.9 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740262a5",
   "metadata": {},
   "source": [
    "### Custom Embbedings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb74a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "bert_model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58202eb4",
   "metadata": {},
   "source": [
    "### Custom UMAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095cc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33ee73",
   "metadata": {},
   "source": [
    "### Custom HDBSCAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87c9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size = 51,\n",
    "                                metric='euclidean', \n",
    "                                cluster_selection_method='eom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf5070",
   "metadata": {},
   "source": [
    "### Custom vectorizer model model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cda8e376",
   "metadata": {
    "id": "cda8e376"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(ngram_range=(2, 2), stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c58db",
   "metadata": {},
   "source": [
    "### Initializing BERTopic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a980c25",
   "metadata": {
    "id": "9a980c25"
   },
   "outputs": [],
   "source": [
    "docs = trump_tweets\n",
    "\n",
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic(#language = 'english',\n",
    "                       embedding_model=bert_model,\n",
    "                       top_n_words=10,\n",
    "                       #n_gram_range=(1, 2),\n",
    "                       #min_topic_size=50,   \n",
    "                       nr_topics = 'auto',\n",
    "                       umap_model=umap_model,\n",
    "                       hdbscan_model=hdbscan_model\n",
    "                       vectorizer_model=vectorizer_model,\n",
    "                       low_memory=True,\n",
    "                       calculate_probabilities=False, \n",
    "                       verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799676e",
   "metadata": {
    "id": "4799676e"
   },
   "source": [
    "### Generating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825bfd9",
   "metadata": {
    "id": "5825bfd9"
   },
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(docs.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578e2903",
   "metadata": {},
   "source": [
    "### Serialize models, topics and docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee49a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4999633",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"./models/trump_all_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66581c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_topics = pd.DataFrame(topics)\n",
    "trump_topics.to_csv('./models/trump_all_topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_docs = {topic: [] for topic in set(topics)}\n",
    "for topic, doc in zip(topics, docs.text):\n",
    "    topic_docs[topic].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44699101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "t_values_favor = [65,10,49,120,97,18,12]\n",
    "t_values_against = [86,37,238,22,34,98,4]\n",
    "t_values_none = [-1]\n",
    "\n",
    "with open('./datasets/trump/favor_trump.json', 'w') as file:\n",
    "     for t in t_values_favor:\n",
    "        file.write(json.dumps(topic_docs[t])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c46f3b",
   "metadata": {},
   "source": [
    "### Load models,topics and docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e885ba24",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_rebuild_function' on <module 'numba.core.serialize' from 'C:\\\\Users\\\\inf\\\\Anaconda3\\\\lib\\\\site-packages\\\\numba\\\\core\\\\serialize.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5948/4094993086.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtopic_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./models/provaxxers_all_mpnet_base_v2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#topics = topic_model.get_topics()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bertopic\\_bertopic.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, path, embedding_model)\u001b[0m\n\u001b[0;32m   1294\u001b[0m                 \u001b[0mtopic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m                 \u001b[0mtopic_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_reduce\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1587\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m         \u001b[0mstack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1590\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mREDUCE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numba\\core\\serialize.py\u001b[0m in \u001b[0;36m_unpickle__CustomPickled\u001b[1;34m(serialized)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mUses\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mNumbaPickler\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mctor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_CustomPickled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_rebuild_function' on <module 'numba.core.serialize' from 'C:\\\\Users\\\\inf\\\\Anaconda3\\\\lib\\\\site-packages\\\\numba\\\\core\\\\serialize.py'>"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic.load(\"./models/provaxxers_all_mpnet_base_v2\")\n",
    "#topics = topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd623986",
   "metadata": {},
   "source": [
    "### Visualize topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e928d",
   "metadata": {
    "id": "1f7e928d"
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c143ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_docs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f147bfe",
   "metadata": {
    "id": "4f147bfe"
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b39ab",
   "metadata": {
    "id": "1e2b39ab"
   },
   "source": [
    "### Reducing the number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df7dce",
   "metadata": {
    "id": "31df7dce"
   },
   "outputs": [],
   "source": [
    "newTopics, newProbs = topic_model.reduce_topics(docs.text, topics, probs, nr_topics=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392913af",
   "metadata": {
    "id": "392913af"
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa33064",
   "metadata": {
    "id": "8fa33064"
   },
   "outputs": [],
   "source": [
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264570f",
   "metadata": {
    "id": "1264570f"
   },
   "outputs": [],
   "source": [
    "topic_model.get_representative_docs(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a073e5ab",
   "metadata": {
    "id": "a073e5ab"
   },
   "source": [
    "### Dynamic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848f875",
   "metadata": {
    "id": "6848f875"
   },
   "outputs": [],
   "source": [
    "timestamps = docs.created_at.to_list()\n",
    "tweets = docs.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f79ee",
   "metadata": {
    "id": "779f79ee"
   },
   "outputs": [],
   "source": [
    "topics_over_time = topic_model.topics_over_time(docs=tweets, \n",
    "                                                topics=newTopics,                                                                                           \n",
    "                                                timestamps=timestamps, \n",
    "                                                global_tuning=True,\n",
    "                                                evolution_tuning=True, \n",
    "                                                nr_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca25ac",
   "metadata": {
    "id": "45ca25ac"
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f568f0",
   "metadata": {
    "id": "75f568f0"
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sbbd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
